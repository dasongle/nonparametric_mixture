\relax 
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\citation{RabJua86,Clark90,HofRafHan02,BleNgJor03}
\citation{HsuKakZha09,ParSonXin11,SonParXin11,FosRodUng12,AnandkumarEtal:tensor12,AnandkumarEtal:twosvd12,Franz13}
\citation{DemLaiRub77}
\citation{AnandkumarEtal:tensor12,Hsu13}
\citation{AnandkumarEtal:tensor12,Hsu13}
\citation{AnandkumarEtal:tensor12}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1}}
\newlabel{sec:intro}{{1}{1}{Introduction\relax }{section.1}{}}
\citation{SonParXin11,SonDai13,SgoJanPetSch13}
\citation{SchTsuVer04}
\citation{SmoGreSonSch07,SriGreFukLanetal08}
\@writefile{toc}{\contentsline {section}{\numberline {2}Notation}{2}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Kernel Embedding of Distributions}{2}{section.3}}
\newlabel{sec:embedding}{{3}{2}{Kernel Embedding of Distributions\relax }{section.3}{}}
\citation{SriGreFukLanetal08}
\citation{GreBorRasSchetal12}
\citation{GreFukTeoSonetal08}
\citation{KolBad09}
\newlabel{eq:embedding}{{1}{3}{Kernel Embedding of Distributions\relax }{equation.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Kernel Embedding as Multi-Linear Operator}{3}{subsection.3.1}}
\citation{SmoGreSonSch07}
\citation{FinSch01}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Finite Sample Estimate}{4}{subsection.3.2}}
\newlabel{eq:empirical_embedding}{{4}{4}{Finite Sample Estimate\relax }{equation.3.4}{}}
\newlabel{eq:empirical_covariance}{{5}{4}{Finite Sample Estimate\relax }{equation.3.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Multi-View Latent Variable Models}{4}{section.4}}
\newlabel{fig:exchangeable}{{1(a)}{5}{Subfigure 1(a)\relax }{subfigure.1.1}{}}
\newlabel{sub@fig:exchangeable}{{(a)}{5}{Subfigure 1(a)\relax }{subfigure.1.1}{}}
\newlabel{fig:hmm}{{1(b)}{5}{Subfigure 1(b)\relax }{subfigure.1.2}{}}
\newlabel{sub@fig:hmm}{{(b)}{5}{Subfigure 1(b)\relax }{subfigure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Examples of multi-view latent variable models. }}{5}{figure.1}}
\newlabel{fig:graphical-model}{{1}{5}{Examples of multi-view latent variable models}{figure.1}{}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Na\"ive Bayes model}}}{5}{figure.1}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Hidden Markov model}}}{5}{figure.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Conditional Embedding Operator}{5}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Factorized Kernel Embedding}{5}{subsection.4.2}}
\citation{Allman09}
\newlabel{eq:pair_factorization}{{9}{6}{Factorized Kernel Embedding\relax }{equation.4.9}{}}
\newlabel{eq:triple_factorization}{{10}{6}{Factorized Kernel Embedding\relax }{equation.4.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Identifiability of Parameters}{6}{subsection.4.3}}
\newlabel{eq:joint2}{{11}{6}{Identifiability of Parameters\relax }{equation.4.11}{}}
\newlabel{eq:joint3}{{12}{6}{Identifiability of Parameters\relax }{equation.4.12}{}}
\newlabel{prop:identifiability}{{1}{6}{Identifiability\relax }{theorem.1}{}}
\citation{Hsu13}
\citation{Kruskal:77,DeLathauwerEtal:FOOBI,AnandkumarEtal:overcomplete13}
\citation{AnandkumarEtal:community12}
\@writefile{toc}{\contentsline {section}{\numberline {5}Kernel Algorithm}{7}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Population Case}{7}{subsection.5.1}}
\citation{AnandkumarEtal:community12}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Finite Sample Case}{8}{subsection.5.2}}
\newlabel{sec:sample}{{5.2}{8}{Finite Sample Case\relax }{subsection.5.2}{}}
\citation{AnandkumarEtal:community12}
\citation{AnandkumarEtal:community12}
\@writefile{loa}{\contentsline {algorithm}{\numberline {1}{\ignorespaces KernelSVD($K$, $L$, $k$)}}{9}{algorithm.1}}
\newlabel{alg:svd}{{1}{9}{Finite Sample Case\relax }{ALC@unique.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Sample Complexity}{9}{section.6}}
\newlabel{thm:samplebound}{{2}{9}{Sample Bounds\relax }{theorem.2}{}}
\citation{Hsu13}
\citation{Hsu13}
\citation{Hiroyuki10}
\citation{Hiroyuki10}
\@writefile{toc}{\contentsline {paragraph}{Remarks: }{10}{section*.1}}
\@writefile{toc}{\contentsline {section}{\numberline {7}Experiments}{10}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Synthetic Data}{10}{subsection.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces (a)-(d) Mixture of Gaussian distributions with $k=2,3,4,8$ components. (e)-(h) Mixture of Gaussian/Gamma distribution with $k=2,3,4,8$. For the former case, the performance of kernel spectral algorithm converge to those of EM algorithm for mixture of Gaussian model. For the latter case, the performance of kernel spectral algorithm are consistently much better than EM algorithm for mixture of Gaussian model. Spherical Gaussian spectral algorithm does not work for $k=4,8$, and hence not plotted.}}{11}{figure.2}}
\newlabel{fig:synthetic}{{2}{11}{(a)-(d) Mixture of Gaussian distributions with $k=2,3,4,8$ components. (e)-(h) Mixture of Gaussian/Gamma distribution with $k=2,3,4,8$. For the former case, the performance of kernel spectral algorithm converge to those of EM algorithm for mixture of Gaussian model. For the latter case, the performance of kernel spectral algorithm are consistently much better than EM algorithm for mixture of Gaussian model. Spherical Gaussian spectral algorithm does not work for $k=4,8$, and hence not plotted}{figure.2}{}}
\citation{cytometry_nature}
\citation{cytometry_nature}
\bibstyle{icml2014}
\bibdata{../nonparametric_mixture,../bibfile,../experiment/mlv_kernel}
\bibcite{cytometry_nature}{{1}{2013}{{Aghaeepour et~al.}}{{Aghaeepour, Finak, Consortium, Consortium, Hoos, Mosmann, Brinkman, Gottardo, and Scheuermann}}}
\bibcite{Allman09}{{2}{2009}{{Allman et~al.}}{{Allman, Matias, and Rhodes}}}
\bibcite{AnandkumarEtal:tensor12}{{3}{2012{a}}{{Anandkumar et~al.}}{{Anandkumar, Ge, Hsu, Kakade, and Telgarsky}}}
\bibcite{AnandkumarEtal:community12}{{4}{2013{a}}{{Anandkumar et~al.}}{{Anandkumar, Ge, Hsu, and Kakade}}}
\bibcite{AnandkumarEtal:overcomplete13}{{5}{2013{b}}{{Anandkumar et~al.}}{{Anandkumar, Hsu, Janzamin, and Kakade}}}
\bibcite{AnandkumarEtal:twosvd12}{{6}{2012{b}}{{Anandkumar et~al.}}{{Anandkumar, Foster, Hsu, Kakade, and Liu}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Flow Cytometry Data}{12}{subsection.7.2}}
\bibcite{BleNgJor03}{{7}{2003}{{Blei et~al.}}{{Blei, Ng, and Jordan}}}
\bibcite{Clark90}{{8}{1990}{{Clark}}{{}}}
\bibcite{DeLathauwerEtal:FOOBI}{{9}{2007}{{De~Lathauwer et~al.}}{{De~Lathauwer, Castaing, and Cardoso}}}
\bibcite{DemLaiRub77}{{10}{1977}{{Dempster et~al.}}{{Dempster, Laird, and Rubin}}}
\bibcite{FinSch01}{{11}{2001}{{Fine \& Scheinberg}}{{Fine and Scheinberg}}}
\bibcite{FosRodUng12}{{12}{2012}{{Foster et~al.}}{{Foster, Rodu, and Ungar}}}
\bibcite{GreFukTeoSonetal08}{{13}{2008}{{Gretton et~al.}}{{Gretton, Fukumizu, Teo, Song, Sch{\"o}lkopf, and Smola}}}
\bibcite{GreBorRasSchetal12}{{14}{2012}{{Gretton et~al.}}{{Gretton, Borgwardt, Rasch, Schoelkopf, and Smola}}}
\bibcite{HofRafHan02}{{15}{2002}{{Hoff et~al.}}{{Hoff, Raftery, and Handcock}}}
\bibcite{HsuKakZha09}{{16}{2009}{{Hsu et~al.}}{{Hsu, Kakade, and Zhang}}}
\bibcite{Hsu13}{{17}{2013}{{Hsu \& Kakade}}{{Hsu and Kakade}}}
\bibcite{Hiroyuki10}{{18}{2010}{{Kasahara \& Shimotsu}}{{Kasahara and Shimotsu}}}
\bibcite{Franz13}{{19}{2013}{{Kir\'{a}ly}}{{}}}
\bibcite{KolBad09}{{20}{2009}{{Kolda \& Bader}}{{Kolda and Bader}}}
\bibcite{Kruskal:77}{{21}{1977}{{Kruskal}}{{}}}
\bibcite{ParSonXin11}{{22}{2011}{{Parikh et~al.}}{{Parikh, Song, and Xing}}}
\bibcite{RabJua86}{{23}{1986}{{Rabiner \& Juang}}{{Rabiner and Juang}}}
\bibcite{RosBelVit2010}{{24}{2010}{{Rosasco et~al.}}{{Rosasco, Belkin, and Vito}}}
\bibcite{SchTsuVer04}{{25}{2004}{{Sch{\"o}lkopf et~al.}}{{Sch{\"o}lkopf, Tsuda, and Vert}}}
\bibcite{SgoJanPetSch13}{{26}{2013}{{Sgouritsa et~al.}}{{Sgouritsa, Janzing, Peters, and Sch\"{o}lkopf}}}
\bibcite{SmoGreSonSch07}{{27}{2007}{{Smola et~al.}}{{Smola, Gretton, Song, and {Sch\"olkopf}}}}
\bibcite{SonDai13}{{28}{2013}{{Song \& Dai}}{{Song and Dai}}}
\bibcite{SonParXin11}{{29}{2011}{{Song et~al.}}{{Song, Parikh, and Xing}}}
\bibcite{SriGreFukLanetal08}{{30}{2008}{{Sriperumbudur et~al.}}{{Sriperumbudur, Gretton, Fukumizu, Lanckriet, and Sch{\"{o}}lkopf}}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Kernel spectral algorithm is able to adapt to the shape of the mixture components, while EM algorithm for mixture of Gaussians misfit the Gamma distribution.}}{15}{figure.3}}
\newlabel{fig:shape}{{3}{15}{Kernel spectral algorithm is able to adapt to the shape of the mixture components, while EM algorithm for mixture of Gaussians misfit the Gamma distribution}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Clustering results on DLBCL flow cytometry data. Each group of bars represents F-scores from EM-GMM with diagonal covariances\nobreakspace  {}(blue) and kernel spectral method\nobreakspace  {}(red). The datasets are ordered by increasing sample size.}}{16}{figure.4}}
\newlabel{fig:real_data}{{4}{16}{Clustering results on DLBCL flow cytometry data. Each group of bars represents F-scores from EM-GMM with diagonal covariances~(blue) and kernel spectral method~(red). The datasets are ordered by increasing sample size}{figure.4}{}}
\citation{AnandkumarEtal:twosvd12}
\@writefile{toc}{\contentsline {section}{\numberline {8}Symmetrization}{17}{section.8}}
\newlabel{sec:symmetrization}{{8}{17}{Symmetrization\relax }{section.8}{}}
\citation{AnandkumarEtal:community12}
\citation{AnandkumarEtal:tensor12}
\citation{AnandkumarEtal:community12}
\citation{AnandkumarEtal:community12}
\@writefile{toc}{\contentsline {section}{\numberline {9}Robust Tensor Power Method}{18}{section.9}}
\@writefile{toc}{\contentsline {section}{\numberline {10}Proof of Theorem\nobreakspace  {}\ref  {thm:samplebound}}{18}{section.10}}
\newlabel{app:samplebound}{{10}{18}{Proof of Theorem~\ref {thm:samplebound}\relax }{section.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.1}Recap of Perturbation Bounds for the Tensor Power Method}{18}{subsection.10.1}}
\newlabel{thm:robustpower}{{3}{18}{Recap of Perturbation Bounds for the Tensor Power Method\relax }{theorem.3}{}}
\newlabel{eqn:robustpowerconditions}{{15}{18}{Recap of Perturbation Bounds for the Tensor Power Method\relax }{equation.10.15}{}}
\@writefile{loa}{\contentsline {algorithm}{\numberline {2}{\ignorespaces $\{\lambda , \Phi \}\leftarrow $TensorEigen$(T,\tmspace  +\thinmuskip {.1667em} \{v_i\}_{i\in [L]}, N)$}}{19}{algorithm.2}}
\newlabel{alg:robustpower}{{2}{19}{Robust Tensor Power Method\relax }{algorithm.2}{}}
\citation{AnandkumarEtal:community12}
\@writefile{toc}{\contentsline {subsection}{\numberline {10.2}Concentration Bounds}{20}{subsection.10.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.1}Analysis of Whitening}{20}{subsubsection.10.2.1}}
\newlabel{eqn:pairsexpression}{{16}{20}{Analysis of Whitening\relax }{equation.10.16}{}}
\newlabel{lemma:whiten}{{4}{20}{Whitening perturbation\relax }{theorem.4}{}}
\@writefile{toc}{\contentsline {paragraph}{Remark: }{20}{section*.3}}
\citation{AnandkumarEtal:tensor12}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.2}Tensor Concentration Bounds}{21}{subsubsection.10.2.2}}
\newlabel{eqn:triplesexpression}{{18}{21}{Tensor Concentration Bounds\relax }{equation.10.18}{}}
\newlabel{eqn:epsilonT}{{19}{21}{Tensor perturbation bound\relax }{equation.10.19}{}}
\citation{RosBelVit2010}
\newlabel{eqn:cond1}{{21}{22}{Tensor Concentration Bounds\relax }{equation.10.21}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {10.2.3}Concentration bounds for Empirical Operators}{22}{subsubsection.10.2.3}}
\newlabel{lemma:pairs}{{6}{22}{Concentration bounds for pairs\relax }{theorem.6}{}}
\newlabel{eqn:deltapairs}{{22}{22}{Concentration bounds for pairs\relax }{equation.10.22}{}}
\newlabel{eq:operator_concentration}{{23}{22}{Concentration bounds for pairs\relax }{equation.10.23}{}}
\newlabel{lemma:triples}{{7}{23}{Concentration bounds for triples\relax }{theorem.7}{}}
\newlabel{eqn:deltapairs}{{26}{23}{Concentration bounds for triples\relax }{equation.10.26}{}}
\newlabel{eq:operator_concentration2}{{27}{23}{Concentration bounds for triples\relax }{equation.10.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {11}Experiment on Single Conditional Distribution}{23}{section.11}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces (a)-(d) Mixture of Gaussian distributions with $k=2,3,4,8$ components. (e)-(h) Mixture of Gaussian/Gamma distribution with $k=2,3,4,8$. For the former case, the performance of kernel spectral algorithm converge to those of EM algorithm for mixture of Gaussian model. For the latter case, the performance of kernel spectral algorithm are consistently much better than EM algorithm for mixture of Gaussian model. Spherical Gaussian spectral algorithm does not work for $k=4,8$, and hence not plotted.}}{24}{figure.5}}
\newlabel{fig:sym_case}{{5}{24}{(a)-(d) Mixture of Gaussian distributions with $k=2,3,4,8$ components. (e)-(h) Mixture of Gaussian/Gamma distribution with $k=2,3,4,8$. For the former case, the performance of kernel spectral algorithm converge to those of EM algorithm for mixture of Gaussian model. For the latter case, the performance of kernel spectral algorithm are consistently much better than EM algorithm for mixture of Gaussian model. Spherical Gaussian spectral algorithm does not work for $k=4,8$, and hence not plotted}{figure.5}{}}
