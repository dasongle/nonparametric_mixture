<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<!-- saved from url=(0097)https://cmt.research.microsoft.com/ICML2014/Protected/Author/ViewReviewsForPaper.aspx?paperId=624 -->
<html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>
	Reviews For Paper
</title>
<style>
body
{
	font-family:verdana,arial,helvetica;
}
#header
{
    width: 100%;
    font-size: small;
    background-color:#F7F7F7;
}
.headerSeparator
{
    background-color: #105586;
}
.printThemeText
{
    font-size:small;
}
.printThemeTable td
{
    vertical-align:top;
}
.printThemeGrid th
{
    color:white;
    background:#5D7B9D;
    font-weight:bold;
}
.printThemeGrid
{
    border-collapse:collapse;
}
.printThemeGrid td, .printThemeGrid th
{
    border:solid 1px #D6D3CE;
    padding:4px 4px 4px 4px;
}
.printThemeGrid .row
{ 
    background-color:#F7F6F3;
    color:#333333;
    vertical-align:top;
}
.printThemeGrid .altrow
{ 
    background-color:White;
    color:#284775;
    vertical-align:top;
}
.cellprompt
{
	font-weight:bold;
	white-space:nowrap;
    width:100px;	
}
.paperHeader
{
    background-color:#dee3e7;
    margin:5px 5px 15px 0px;
    width:99%;
    font-family:Verdana;
    font-size:medium;
    font-weight:bold;
}
.sectionHeader
{
    background-color:#dee3e7;
    padding:5px 5px 5px 0px;
    width:99%;
    text-decoration:underline;
    font-family:Verdana;
    font-size:small;
    font-weight:bold;
}
.underlineheader
{
    text-decoration:underline;
    font-weight:bold;
    padding:5px 0px;
}
.response
{
    padding:5px 0px;
}
.reviewerlabel
{
    padding-right:20px;
}
.pageTitle
{
    background-color:#dee3e7;
    padding:5px 5px 5px 5px;
    margin-top:10px;
    width:99%;
    font-family:Verdana;
    font-size:medium;
    font-weight:bold;
}
.submissionDetailsView
{
}
.submissionDetailsView tr
{
    vertical-align:top;
}
.submissionDetailsView td.prompt
{
    font-weight:bold;
}
.submissionDetailsView tr.sectionSeparator
{

}
.submissionDetailsView tr.sectionSeparator td
{
    background-color:#dee3e7;
    padding:5px 5px 5px 5px;
    font-family:Verdana;
    font-size:small;
    font-weight:bold;
    color:Navy;
}
/*CSS Grid View General Definitions*/
.CssGridView
{
    font-size:small; 
}

.CssGridView td, .CssGridView th
{
    padding:4px 4px 4px 4px;
}

/*CSS Compact Grid View General Definitions*/
.CssGridViewCompact img
{
    border-style:none;
    border-width:0px;
}

.CssGridViewCompact
{
    font-size:1em;
    border-style:solid;
    border-color:#D6D3CE;
    border-width:1px;
}

.CssGridViewCompact .hrow a
{
    font-size:1em;
}

.CssGridViewCompact .row a, .CssGridViewCompact .altrow a
{
    font-size:0.8em;
}

.CssGridViewCompact .row .normal a, .CssGridViewCompact .row .normal, .CssGridViewCompact .altrow .normal a, .CssGridViewCompact .altrow .normal
{
    font-size:1em;
}

/*CSS Grid View Header Styles*/
.CssGridView .hrow, .CssGridViewCompact .hrow
{ 
    background-color:#5D7B9D;
    font-weight:bold;
    color:White;
}


.CssGridViewCompact .hrow td
{ 
    border-bottom-width:0px;
}

.CssGridViewCompact .hrow th
{ 
    border-top-width:0px;
    font-size:0.8em;
    vertical-align:top;
    border-left-width:0px;
    border-right-width:0px;
}

.CssGridViewCompact .smaller
{
    font-size:0.8em;
}

/*CSS Grid View Row Styles*/
.CssGridViewCompact .row, .CssGridViewCompact .altrow
{
    border-top-style:solid;
    border-top-color:#D6D3CE;
    border-top-width:1px;
    border-bottom-style:solid;
    border-bottom-color:#D6D3CE;
    border-bottom-width:1px;
}

/*CSS Grid View Header Styles*/
.CssGridViewCompact .hrow .leftborder, .CssGridViewCompact .row .leftborder, .CssGridViewCompact .altrow .leftborder
{
    border-left-width:1px;
    border-left-color:#D6D3CE;
    border-left-style:solid;
}

.CssGridViewCompact .hrow .rightborder, .CssGridViewCompact .row .rightborder, .CssGridViewCompact .altrow .rightborder
{
    border-right-width:1px;
    border-right-color:#D6D3CE;
    border-right-style:solid;
}

.CssGridView .hrow a, .CssGridViewCompact .hrow a
{ 
    color:White;
}
 
.CssGridView .row, .CssGridViewCompact .row
{ 
    background-color:#F7F6F3;
    color:#333333;
    vertical-align:top;
}

.CssGridView .altrow, .CssGridViewCompact .altrow
{ 
    vertical-align:top;
}

.CssGridViewCompact .row td
{ 
    border-left-width:0px;
    border-right-width:0px;
}
 
.CssGridViewCompact .altrow
{ 
    background-color:White;
    color:#284775;
    vertical-align:top;
}

.CssGridView .altrow tr, .CssGridViewCompact .altrow tr, .CssGridView .row tr, .CssGridViewCompact .row tr
{ 
    vertical-align:top;
}
</style>
</head>
<body>
<form name="aspnetForm" method="post" action="./Reviews For Paper_files/Reviews For Paper.html" id="aspnetForm">
<div>
<input type="hidden" name="__VIEWSTATE" id="__VIEWSTATE" value="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">
</div>

<table id="header">
<tbody><tr>
<td width="100%"><a href="http://icml.cc/2014/" target="_blank">ICML 2014</a><br><b>International Conference on Machine Learning </b><br>June 21–26, 2014, Beijing, China</td>
</tr>
<tr class="headerSeparator">
    <td style="height:5px"></td>
</tr>
</tbody></table>
<table id="content"><tbody><tr><td class="contentBorder">&nbsp;</td><td class="contentContainer">
<span id="ctl00_cph_Label4" style="font-size:Small;font-weight:bold;">Reviews For Paper</span>
<span id="ctl00_cph_lblErrorMessage" class="error" style="font-size:Small;"></span>
<div id="ctl00_cph_pnlReviews">
	
    <span style="font-size:Small;">
<table class="nicetable2" style="text-align:left; width: 100%;">
    <tbody><tr id="ctl00_cph_infoSubmission_trTrack">
		<td><b>Track</b></td>
		<td><span id="ctl00_cph_infoSubmission_lblTrack" style="font-size:Small;">Cycle 1</span></td>
	</tr>
	
    <tr>
        <td width="100px"><b>Paper ID</b></td>
        <td><span id="ctl00_cph_infoSubmission_lblPaperId" style="font-size:Small;">624</span></td>
    </tr>
    <tr>
        <td><b>Title</b></td>
        <td><span id="ctl00_cph_infoSubmission_lblPaperTitle" style="font-size:Small;">Nonparametric Estimation of Multi-View Latent Variable Models</span></td>
    </tr>
    
    
    
    
    
</tbody></table></span>
    
    
            <hr>
            <table>
                <tbody><tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl00_Label2" style="font-size:Small;font-weight:bold;">Masked Reviewer ID:</span>
                    </td>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl00_Label1" style="font-size:Small;">Assigned_Reviewer_1</span>
                    </td>
                </tr>
                <tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl00_Label3" style="font-size:Small;font-weight:bold;">Review:</span>
                    </td>
                    <td>
                    </td>
                </tr>
            </tbody></table>
            <div>
		<table cellspacing="0" cellpadding="4" rules="all" border="1" style="color:#333333;border-width:1px;border-style:None;font-family:Verdana;font-size:Small;border-collapse:collapse;">
			<tbody><tr style="color:White;background-color:#5D7B9D;font-weight:bold;">
				<th scope="col">Question</th><th scope="col">&nbsp;</th>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Overall Rating</td><td style="width:80%;">
                            Weak reject
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Reviewer confidence</td><td style="width:80%;">
                            Reviewer is knowledgeable
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Detailed comments for the authors</td><td style="width:80%;">
                            Kernel embedding is a well-known technique to map the distributions into an infinite dimensional RKHS. It is also well known that this mapping is injective. In this paper, authors use this embedding trick to estimate the parameters of a multi-view latent variable model. Authors present a spectral algorithm (based on the spectral decompositions of the gram matrices of different views) to estimate these parameters. <br><br>Since authors use the well-known kernel trick in addition to an existing algorithm to estimate the parameters, the paper is limited in technical novelty. The proposed algorithm, as also mentioned in the paper, is merely a Kernelized version of an existing algorithm. However, it is interesting to see how this algorithm provides a unified framework and subsumes many of the existing algorithms.  <br><br>Results presented in this paper are not convincing enough. It is not clear, in the real dataset, how authors came up with splitting those 5 dimensions into three different views.  Although it is clear in the formulation, it is not clear in this experiment that what a view means. In general, a view can be created in two ways – one is, you can divide the dataset along the dimensions to create different views (as you are doing), and second, you can group examples themselves, each group representing one view. It seems that in this experiment, you are using both kind of views. If true, it is important to see why one needs to split the dataset along the feature dimesnsion to create these different views, and how one can come up with such split. <br><br>The baselines used in this paper are rather inferior, one of them is EM, which is generative. Anywhere where the underlying generative assumption is wrong, the method is bound to perform worse. Similarly, the other baseline which is not only generative but also restrictive in the sense that the center should like on a k-dimensional span. It would be interesting to see the performance of the proposed approach in the light of other parametric methods. <br><br>Authors claims to have experimented on 30 datasets, the figure only shows 24 datasets.<br>
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Summary of evaluation / Paper's main strengths and weaknesses</td><td style="width:80%;">
                            .
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">I have read and considered the authors' response. (To be answered only after the response period.)</td><td style="width:80%;">
                            No
                        </td>
			</tr>
		</tbody></table>
	</div>
            
        
            <hr>
            <table>
                <tbody><tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl01_Label2" style="font-size:Small;font-weight:bold;">Masked Reviewer ID:</span>
                    </td>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl01_Label1" style="font-size:Small;">Assigned_Reviewer_3</span>
                    </td>
                </tr>
                <tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl01_Label3" style="font-size:Small;font-weight:bold;">Review:</span>
                    </td>
                    <td>
                    </td>
                </tr>
            </tbody></table>
            <div>
		<table cellspacing="0" cellpadding="4" rules="all" border="1" style="color:#333333;border-width:1px;border-style:None;font-family:Verdana;font-size:Small;border-collapse:collapse;">
			<tbody><tr style="color:White;background-color:#5D7B9D;font-weight:bold;">
				<th scope="col">Question</th><th scope="col">&nbsp;</th>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Overall Rating</td><td style="width:80%;">
                            Weak reject
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Reviewer confidence</td><td style="width:80%;">
                            Reviewer is knowledgeable
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Detailed comments for the authors</td><td style="width:80%;">
                            The paper combines spectral methods with kernel mean embeddings to infer latent variable models.<br><br>I'm not an expert for spectral methods, though, there is an important point on the embedding side that is worth raising. The strength of embeddings lies in the calculation of integrals and expectations not in density estimation. Since the task in the paper is to learn latent variable models the authors seem forced to move away from expectations towards densities. <br><br>This puts them in a setting that is not natural for the embeddings and my feeling is that the authors are well aware of this since the necessary move from expectations to densities is pushed aside as much as possible. The main description of how they do this is L340-L343 that is they set<br><br>p(x|h) = E_(y~h) k(x,y) <br><br>where E_(y~h) is the inferred mean embedding for the case that the latent variable is h. Now this is not a great way to estimate a density. First of all you need a kernel which concentrates around x; think of a delta-distribution. So rule out polynomial kernels and, I guess, kernels on structures like graphs.   <br><br>It is possible, and I think this is the only reasonable setting, to use kernels which concentrate around x and have a bandwidth parameter that shrinks towards zero with sample size. Though, you are getting very close to kernel density estimation here and one wonders what you gain from the embedding approach. In particular, why not do directly a kernel density estimation for the conditionals instead of estimating the densities through the embeddings? <br><br>In my opinion this is a really crucial point and at the very least a proper discussion is needed why either kernel density estimation cannot be performed (I don't see why one shouldn't be able to use it)  or, if it can, why there is no comparison to kernel density estimation. In particular, arguments are needed why embeddings are worth the effort and experimental results to support the claims. <br><br>I also find the current experimental discussion about how the density extraction from the embeddings plays in insufficient. In 7.1 probabilities are directly estimated, in 7.2 the maximum posterior -- which I guess means probabilities for the h's are estimated and then the highest probability is chosen? The bandwidth will here be an important factor to concentrate in the right rate around x. It is said some form of cross validation is performed in 7.2 using the log-likelihood. Some more details would be appreciated. <br>
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Summary of evaluation / Paper's main strengths and weaknesses</td><td style="width:80%;">
                            The paper is mostly presented well. However, I have considerable concerns about the extraction of densities from mean embeddings. This is rather unnatural and I miss a clear argument why this is something one wants to do and why other non-parametric methods like kernel density estimation are not suitable.
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">I have read and considered the authors' response. (To be answered only after the response period.)</td><td style="width:80%;">
                            No
                        </td>
			</tr>
		</tbody></table>
	</div>
            
        
            <hr>
            <table>
                <tbody><tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl02_Label2" style="font-size:Small;font-weight:bold;">Masked Reviewer ID:</span>
                    </td>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl02_Label1" style="font-size:Small;">Assigned_Reviewer_4</span>
                    </td>
                </tr>
                <tr>
                    <td>
                        <span id="ctl00_cph_gvReviews_ctl02_Label3" style="font-size:Small;font-weight:bold;">Review:</span>
                    </td>
                    <td>
                    </td>
                </tr>
            </tbody></table>
            <div>
		<table cellspacing="0" cellpadding="4" rules="all" border="1" style="color:#333333;border-width:1px;border-style:None;font-family:Verdana;font-size:Small;border-collapse:collapse;">
			<tbody><tr style="color:White;background-color:#5D7B9D;font-weight:bold;">
				<th scope="col">Question</th><th scope="col">&nbsp;</th>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Overall Rating</td><td style="width:80%;">
                            Weak accept
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Reviewer confidence</td><td style="width:80%;">
                            Reviewer is knowledgeable
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">Detailed comments for the authors</td><td style="width:80%;">
                            This paper brings together two emerging themes: the first pertains to the resurgence of the method of moments for estimating latent variable models using approximate tensor decomposition schemes (Anandkumar, Hsu, Kakade et al, 2012), and the second theme pertains to RKHS embeddings of probability distributions for extending spectral techniques to non-parametric estimation settings (Smola et al, 2007 and several recent papers). The focus in this paper is on "multi-view" latent variable models where observed variables are conditionally independent given a discrete hidden  variable. Moment tensors in the kernelized settings are replaced by higher order covariance operators, whose tensor decomposition after appropriate whitening steps yields the mean embeddings of the underlying conditional distributions. The algorithm can be implemented on Gram matrices given a set of observations. The paper extends previous sample complexity results for this kernelized setting and some promising empirical results are reported.<br><br>Overall, the paper is well written and the contributions follow naturally from previous related literature.<br><br>Do other models such as ICA or LDA also admit such a kernelization?<br><br>Section 5.2 should be rewritten with pure kernelized notation (no feature spaces - only Gram matrices). Is Algorithm 1 only a partial description - e.g., I do not see the tensor power method invoked anywhere there. As I understand it, the power method is run on deflated versions of the tensor for i=1-to-k. Can these steps be entirely implemented with Gram matrices? If so please clarify, as such a full description will help appreciate the full computation complexity of the proposed algorithm. For the case of p views, are these Gram matrices of size pm x pm - if so scalability becomes a concern rather quickly?<br><br>Last line of the paper: "more robustness" -&gt; "more robust"<br><br>It may be useful to provide a short proof sketch for Theorem 2, or atleast how the theorem relates to previous results. What is being added to the proof technique in this specific kernelized context? This will help make the paper a bit more self-contained.<br><br>In Figure 4, the benefits of the kernel spectral approach over EM-GMM are not consistent. How was the claim that these are datasets where the multiview assumption is "heavily violated" verified? As in Figure 2, is Hsu et al not applicable on this problem for some reason? It would have made the paper stronger to provide more empirical support on real datasets.
                        </td>
			</tr><tr style="color:#284775;background-color:White;">
				<td style="width:20%;">Summary of evaluation / Paper's main strengths and weaknesses</td><td style="width:80%;">
                            Nice paper combining RKHS embedding ideas with tensor decomposition techniques for latent variable estimation - though in some respects the algorithmic extensions are straightforward. The proposed approach is backed with empirical results and theoretical analyses. The empirical section could be strengthened. The paper can be improved by making some sections more self-contained and clarifying precisely how some of the analysis builds on prior results.
                        </td>
			</tr><tr style="color:#333333;background-color:#F7F6F3;">
				<td style="width:20%;">I have read and considered the authors' response. (To be answered only after the response period.)</td><td style="width:80%;">
                            No
                        </td>
			</tr>
		</tbody></table>
	</div>
            
        
    <br>
    <br>

</div>
</td><td class="contentBorder">&nbsp;</td></tr></tbody></table>
</form>


<div class="vimiumReset vimiumHUD" style="right: 315px; opacity: 1;">Vimium has been updated to      <a class="vimiumReset" href="https://chrome.google.com/extensions/detail/dbepggeogbaibhgnhhndojpepiihcmeb">      1.44</a>.<a class="vimiumReset close-button" href="https://cmt.research.microsoft.com/ICML2014/Protected/Author/ViewReviewsForPaper.aspx?paperId=624#">x</a></div></body></html>